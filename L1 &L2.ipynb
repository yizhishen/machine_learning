{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证L1的稀疏性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(L1）逻辑回归的参数w为：  [[ 0.          0.          0.00380416  0.          0.0708005  -0.29471144\n",
      "   0.         -0.34068405  0.          0.78465456  0.          0.10128216\n",
      "   0.          0.          0.         -0.04115284  0.          0.\n",
      "   0.41517583  0.        ]]\n",
      "(L2）逻辑回归的参数w为：  [[-0.06020774 -0.08587293  0.06269959  0.0218838   0.36622515 -0.45899841\n",
      "   0.11456309 -0.44218794 -0.24780618  0.87767764 -0.32403048  0.27800343\n",
      "   0.34313572  0.16393398 -0.14322159 -0.22759078  0.09331433 -0.22950935\n",
      "   0.48553032  0.1213868 ]]\n"
     ]
    }
   ],
   "source": [
    "#随机生成样本数据，二分类问题，每个类别生成5000个样本数据\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "num_sample = 100#生成正负样本各100个\n",
    "#利用高斯分布来生成样本，首先需要生成covariance matrix\n",
    "#由于假设我们生成20维的特征向量，所以矩阵大小为20*20\n",
    "rand_m = np.random.rand(20,20)\n",
    "#保证矩阵为psd矩阵（半正定）\n",
    "cov = np.matmul(rand_m.T,rand_m)\n",
    "\n",
    "#通过高斯分布生成样本\n",
    "x1 = np.random.multivariate_normal(np.random.rand(20),cov,num_sample) \n",
    "# mean, covariance [], size,\n",
    "x2 = np.random.multivariate_normal(np.random.rand(20)+5,cov,num_sample)\n",
    "X = np.vstack((x1, x2)).astype(np.float32)\n",
    "#Stack arrays in sequence vertically (row wise).    \n",
    "#numpy.hstack means stack arrayshorizontally (column wise)\n",
    "y= np.hstack((np.zeros(num_sample),np.ones(num_sample)))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#使用L1的正则，C为控制正则的参数。C值越大，正则项的强度越弱\n",
    "#solver:选择不同的优化器\n",
    "clf = LogisticRegression(fit_intercept=True,C=0.1,penalty='l1',solver='liblinear')\n",
    "clf.fit(X,y)\n",
    "print(\"(L1）逻辑回归的参数w为： \",clf.coef_)\n",
    "##使用L2的正则，C为控制正则的参数。C值越大，正则项的强度越弱\n",
    "clf = LogisticRegression(fit_intercept=True,C=0.1,penalty='l2',solver='liblinear')\n",
    "clf.fit(X,y)\n",
    "print(\"(L2）逻辑回归的参数w为： \",clf.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
